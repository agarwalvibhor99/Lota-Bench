/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config_alfred': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
{'planner': {'model_name': '/notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507', 'use_accelerate_device_map': True, 'load_in_8bit': True, 'device': 'cuda', 'max_steps': 25, 'random_seed': 0, 'scoring_batch_size': 4, 'score_function': 'sum', 'scoring_mode': 'naive', 'use_predefined_prompt': False, 'hf_auth_token': '', 'openai_api_key': ''}, 'name': 'alfred', 'out_dir': '${hydra:run.dir}', 'prompt': {'num_examples': 6, 'splitter': '', 'prefix': "Robot: Hi there, I'm a robot operating in a home.\nRobot: You can ask me to do various tasks and I'll tell you the sequence of actions I would do to accomplish your task.\n", 'example_file_path': 'resource/alfred_examples_for_prompt.json'}, 'alfred': {'x_display': '1', 'eval_set': 'valid_seen', 'eval_portion_in_percent': 5, 'random_seed_for_eval_subset': 1}}
[2025-12-03 03:47:14,845][src.alfred.alfred_evaluator][INFO] - planner:
  model_name: /notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507
  use_accelerate_device_map: true
  load_in_8bit: true
  device: cuda
  max_steps: 25
  random_seed: 0
  scoring_batch_size: 4
  score_function: sum
  scoring_mode: naive
  use_predefined_prompt: false
  hf_auth_token: ''
  openai_api_key: ''
name: alfred
out_dir: ${hydra:run.dir}
prompt:
  num_examples: 6
  splitter: ''
  prefix: 'Robot: Hi there, I''m a robot operating in a home.

    Robot: You can ask me to do various tasks and I''ll tell you the sequence of actions
    I would do to accomplish your task.

    '
  example_file_path: resource/alfred_examples_for_prompt.json
alfred:
  x_display: '1'
  eval_set: valid_seen
  eval_portion_in_percent: 5
  random_seed_for_eval_subset: 1

/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Loading LLM and tokenizer: /notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507
[2025-12-03 03:47:19,910][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████████████████                                                                          | 1/3 [00:09<00:19,  9.60s/it]Loading checkpoint shards:  67%|██████████████████████████████████████████████████████████████████████████                                     | 2/3 [00:19<00:09,  9.71s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  5.41s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.56s/it]
Loading done

[2025-12-03 03:47:40,454][src.alfred.alfred_task_planner][INFO] - # of skills: 214
[2025-12-03 03:47:40,457][src.alfred.alfred_task_planner][INFO] - [' done', ' find a bowl', ' find a tennis racket', ' find a book', ' find a bathtub', ' find a candle', ' find a hand towel', ' find a cloth', ' find a coffee table', ' find a soap bar', ' find a bed', ' find a toilet paper hanger', ' find a side table', ' find a newspaper', ' find an egg', ' find a fridge', ' find a coffee machine', ' find a microwave', ' find a spoon', ' find a statue', ' find an ottoman', ' find a faucet', ' find a fork', ' find a spray bottle', ' find a shelf', ' find an arm chair', ' find an apple', ' find a pepper shaker', ' find a bread', ' find a cart', ' find a pot', ' find a cup', ' find a toilet paper', ' find a toilet', ' find a knife', ' find a credit card', ' find a vase', ' find a salt shaker', ' find a laptop', ' find a remote control', ' find a box', ' find a baseball bat', ' find a tissue box', ' find a drawer', ' find a CD', ' find a dish sponge', ' find a butter knife', ' find a dresser', ' find a plate', ' find a pen', ' find a counter top', ' find a dining table', ' find a soap bottle', ' find a lettuce', ' find a pencil', ' find a kettle', ' find a desk', ' find a cell phone', ' find a watch', ' find a desk lamp', ' find a wine bottle', ' find a tomato', ' find a cabinet', ' find a pillow', ' find a glassbottle', ' find a floor lamp', ' find an alarm clock', ' find a plunger', ' find a ladle', ' find a potato', ' find a garbage can', ' find a watering can', ' find a stove burner', ' find a key chain', ' find a mug', ' find a basket ball', ' find a sink', ' find a spatula', ' find a safe', ' find a pan', ' find a sofa', ' pick up the key chain', ' put down the key chain', ' pick up the potato', ' put down the potato', ' pick up the pot', ' put down the pot', ' pick up the pen', ' put down the pen', ' pick up the candle', ' put down the candle', ' pick up the CD', ' put down the CD', ' pick up the pan', ' put down the pan', ' pick up the watch', ' put down the watch', ' pick up the newspaper', ' put down the newspaper', ' pick up the hand towel', ' put down the hand towel', ' pick up the spray bottle', ' put down the spray bottle', ' pick up the baseball bat', ' put down the baseball bat', ' pick up the bread', ' put down the bread', ' pick up the cell phone', ' put down the cell phone', ' pick up the book', ' put down the book', ' pick up the lettuce', ' put down the lettuce', ' pick up the credit card', ' put down the credit card', ' pick up the mug', ' put down the mug', ' pick up the alarm clock', ' put down the alarm clock', ' pick up the kettle', ' put down the kettle', ' pick up the toilet paper', ' put down the toilet paper', ' pick up the bowl', ' put down the bowl', ' pick up the fork', ' put down the fork', ' pick up the box', ' put down the box', ' pick up the egg', ' put down the egg', ' pick up the spoon', ' put down the spoon', ' pick up the tissue box', ' put down the tissue box', ' pick up the apple', ' put down the apple', ' pick up the tennis racket', ' put down the tennis racket', ' pick up the ladle', ' put down the ladle', ' pick up the wine bottle', ' put down the wine bottle', ' pick up the cloth', ' put down the cloth', ' pick up the plunger', ' put down the plunger', ' pick up the soap bar', ' put down the soap bar', ' pick up the pencil', ' put down the pencil', ' pick up the laptop', ' put down the laptop', ' pick up the remote control', ' put down the remote control', ' pick up the basket ball', ' put down the basket ball', ' pick up the dish sponge', ' put down the dish sponge', ' pick up the cup', ' put down the cup', ' pick up the spatula', ' put down the spatula', ' pick up the salt shaker', ' put down the salt shaker', ' pick up the plate', ' put down the plate', ' pick up the pepper shaker', ' put down the pepper shaker', ' pick up the pillow', ' put down the pillow', ' pick up the glassbottle', ' put down the glassbottle', ' pick up the soap bottle', ' put down the soap bottle', ' pick up the knife', ' put down the knife', ' pick up the statue', ' put down the statue', ' pick up the tomato', ' put down the tomato', ' pick up the butter knife', ' put down the butter knife', ' pick up the watering can', ' put down the watering can', ' pick up the vase', ' put down the vase', ' open the safe', ' close the safe', ' open the laptop', ' close the laptop', ' open the fridge', ' close the fridge', ' open the box', ' close the box', ' open the microwave', ' close the microwave', ' open the cabinet', ' close the cabinet', ' open the drawer', ' close the drawer', ' slice the potato', ' slice the lettuce', ' slice the tomato', ' slice the apple', ' slice the bread', ' turn on the microwave', ' turn off the microwave', ' turn on the desk lamp', ' turn off the desk lamp', ' turn on the floor lamp', ' turn off the floor lamp', ' turn on the faucet', ' turn off the faucet']
Found path: /root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64
Mono path[0] = '/root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64_Data/Managed'
Mono config path = '/root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64_Data/Mono/etc'
Unable to preload the following plugins:
	ScreenSelector.so
Display 0 'screen': 1024x768 (primary device).
Logging to /root/.config/unity3d/Allen Institute for Artificial Intelligence/AI2-Thor/Player.log
ALSA lib confmisc.c:855:(parse_card) cannot find card '0'
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory
ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory
ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default
ALSA lib confmisc.c:855:(parse_card) cannot find card '0'
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory
ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory
ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default
{'tests_seen': 1533,
 'tests_unseen': 1529,
 'train': 21023,
 'valid_seen': 820,
 'valid_unseen': 821}
ThorEnv started.
  0%|                                                                                                                                                 | 0/34 [00:00<?, ?it/s][2025-12-03 03:47:45,402][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-SoapBar-None-Cart-401/trial_T20190907_054906_608944'}
[2025-12-03 03:47:45,408][src.alfred.alfred_evaluator][INFO] - Evaluating (1/34): alfred/data/json_2.1.0/pick_and_place_simple-SoapBar-None-Cart-401/trial_T20190907_054906_608944
Resetting ThorEnv
[2025-12-03 03:47:57,138][src.alfred.alfred_evaluator][INFO] - Task: To place the soap on the rack.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:47:57,455][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
  3%|████                                                                                                                                     | 1/34 [00:12<06:37, 12.05s/it][2025-12-03 03:47:57,456][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 5, 'task': 'pick_cool_then_place_in_recep-Plate-None-Cabinet-27/trial_T20190906_173120_350651'}
[2025-12-03 03:47:57,466][src.alfred.alfred_evaluator][INFO] - Evaluating (2/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-Plate-None-Cabinet-27/trial_T20190906_173120_350651
Resetting ThorEnv
[2025-12-03 03:48:10,865][src.alfred.alfred_evaluator][INFO] - Task: Put a plate in a cabinet.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:10,874][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
  6%|████████                                                                                                                                 | 2/34 [00:25<06:51, 12.86s/it][2025-12-03 03:48:10,874][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Book-None-Sofa-229/trial_T20190907_042856_259139'}
[2025-12-03 03:48:10,895][src.alfred.alfred_evaluator][INFO] - Evaluating (3/34): alfred/data/json_2.1.0/pick_and_place_simple-Book-None-Sofa-229/trial_T20190907_042856_259139
Resetting ThorEnv
[2025-12-03 03:48:18,868][src.alfred.alfred_evaluator][INFO] - Task: Move a book from a desk to a sofa.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:18,875][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
  9%|████████████                                                                                                                             | 3/34 [00:33<05:29, 10.64s/it][2025-12-03 03:48:18,876][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-DishSponge-None-Cart-401/trial_T20190907_024634_972453'}
[2025-12-03 03:48:18,883][src.alfred.alfred_evaluator][INFO] - Evaluating (4/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-DishSponge-None-Cart-401/trial_T20190907_024634_972453
Resetting ThorEnv
[2025-12-03 03:48:21,552][src.alfred.alfred_evaluator][INFO] - Task: Put a clean sponge on a metal rack.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:21,560][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 12%|████████████████                                                                                                                         | 4/34 [00:36<03:44,  7.50s/it][2025-12-03 03:48:21,560][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_cool_then_place_in_recep-BreadSliced-None-DiningTable-27/trial_T20190908_075813_148407'}
[2025-12-03 03:48:21,573][src.alfred.alfred_evaluator][INFO] - Evaluating (5/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-BreadSliced-None-DiningTable-27/trial_T20190908_075813_148407
Resetting ThorEnv
[2025-12-03 03:48:23,209][src.alfred.alfred_evaluator][INFO] - Task: Slice bread and chill it in the fridge. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:23,217][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 15%|████████████████████▏                                                                                                                    | 5/34 [00:37<02:36,  5.39s/it][2025-12-03 03:48:23,217][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-ToiletPaper-None-ToiletPaperHanger-415/trial_T20190908_050518_595510'}
[2025-12-03 03:48:23,221][src.alfred.alfred_evaluator][INFO] - Evaluating (6/34): alfred/data/json_2.1.0/pick_and_place_simple-ToiletPaper-None-ToiletPaperHanger-415/trial_T20190908_050518_595510
Resetting ThorEnv
[2025-12-03 03:48:26,186][src.alfred.alfred_evaluator][INFO] - Task: Put a roll of toilet paper on the toilet paper holder.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:26,194][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 18%|████████████████████████▏                                                                                                                | 6/34 [00:40<02:07,  4.57s/it][2025-12-03 03:48:26,194][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-ButterKnife-None-DiningTable-16/trial_T20190909_114508_617301'}
[2025-12-03 03:48:26,202][src.alfred.alfred_evaluator][INFO] - Evaluating (7/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-ButterKnife-None-DiningTable-16/trial_T20190909_114508_617301
Resetting ThorEnv
[2025-12-03 03:48:30,016][src.alfred.alfred_evaluator][INFO] - Task: Put a clean butter knife on a round white table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:30,023][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 21%|████████████████████████████▏                                                                                                            | 7/34 [00:44<01:56,  4.33s/it][2025-12-03 03:48:30,024][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-HandTowel-None-BathtubBasin-419/trial_T20190908_023400_293044'}
[2025-12-03 03:48:30,029][src.alfred.alfred_evaluator][INFO] - Evaluating (8/34): alfred/data/json_2.1.0/pick_and_place_simple-HandTowel-None-BathtubBasin-419/trial_T20190908_023400_293044
Resetting ThorEnv
[2025-12-03 03:48:33,666][src.alfred.alfred_evaluator][INFO] - Task: Place a towel in the bath tub.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:33,673][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 24%|████████████████████████████████▏                                                                                                        | 8/34 [00:48<01:46,  4.11s/it][2025-12-03 03:48:33,673][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106'}
[2025-12-03 03:48:33,679][src.alfred.alfred_evaluator][INFO] - Evaluating (9/34): alfred/data/json_2.1.0/pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106
Resetting ThorEnv
[2025-12-03 03:48:36,220][src.alfred.alfred_evaluator][INFO] - Task: Move a newspaper from a dresser to a black couch.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:36,228][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 26%|████████████████████████████████████▎                                                                                                    | 9/34 [00:50<01:30,  3.63s/it][2025-12-03 03:48:36,228][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934'}
[2025-12-03 03:48:36,237][src.alfred.alfred_evaluator][INFO] - Evaluating (10/34): alfred/data/json_2.1.0/pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934
Resetting ThorEnv
[2025-12-03 03:48:38,655][src.alfred.alfred_evaluator][INFO] - Task: Put a bottle on the back of a newspaper.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:38,662][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 29%|████████████████████████████████████████                                                                                                | 10/34 [00:53<01:18,  3.26s/it][2025-12-03 03:48:38,662][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_cool_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190907_073447_193556'}
[2025-12-03 03:48:38,680][src.alfred.alfred_evaluator][INFO] - Evaluating (11/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190907_073447_193556
Resetting ThorEnv
[2025-12-03 03:48:42,451][src.alfred.alfred_evaluator][INFO] - Task: Place a cold potato slice in the sink.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:42,461][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 32%|████████████████████████████████████████████                                                                                            | 11/34 [00:57<01:18,  3.42s/it][2025-12-03 03:48:42,462][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-Tomato-None-CounterTop-25/trial_T20190909_012550_586494'}
[2025-12-03 03:48:42,470][src.alfred.alfred_evaluator][INFO] - Evaluating (12/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Tomato-None-CounterTop-25/trial_T20190909_012550_586494
Resetting ThorEnv
[2025-12-03 03:48:44,912][src.alfred.alfred_evaluator][INFO] - Task: Put a cold, clean tomato on the counter.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:44,922][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 35%|████████████████████████████████████████████████                                                                                        | 12/34 [00:59<01:08,  3.13s/it][2025-12-03 03:48:44,922][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-Watch-Bowl-Shelf-326/trial_T20190909_031836_927615'}
[2025-12-03 03:48:44,928][src.alfred.alfred_evaluator][INFO] - Evaluating (13/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-Watch-Bowl-Shelf-326/trial_T20190909_031836_927615
Resetting ThorEnv
[2025-12-03 03:48:48,323][src.alfred.alfred_evaluator][INFO] - Task: Put a bowl with the watch in it on the shelf.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:48,331][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 38%|████████████████████████████████████████████████████                                                                                    | 13/34 [01:02<01:07,  3.21s/it][2025-12-03 03:48:48,331][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_simple-CreditCard-None-Drawer-227/trial_T20190909_010644_297017'}
[2025-12-03 03:48:48,337][src.alfred.alfred_evaluator][INFO] - Evaluating (14/34): alfred/data/json_2.1.0/pick_and_place_simple-CreditCard-None-Drawer-227/trial_T20190909_010644_297017
Resetting ThorEnv
[2025-12-03 03:48:51,790][src.alfred.alfred_evaluator][INFO] - Task: Place a credit card into a drawer
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:51,797][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 41%|████████████████████████████████████████████████████████                                                                                | 14/34 [01:06<01:05,  3.29s/it][2025-12-03 03:48:51,798][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Cloth-None-Toilet-413/trial_T20190908_175253_104175'}
[2025-12-03 03:48:51,807][src.alfred.alfred_evaluator][INFO] - Evaluating (15/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Cloth-None-Toilet-413/trial_T20190908_175253_104175
Resetting ThorEnv
[2025-12-03 03:48:54,660][src.alfred.alfred_evaluator][INFO] - Task: Put a clean rag on the toilet. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:54,668][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 44%|████████████████████████████████████████████████████████████                                                                            | 15/34 [01:09<01:00,  3.16s/it][2025-12-03 03:48:54,668][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_heat_then_place_in_recep-Mug-None-SideTable-21/trial_T20190909_090729_088825'}
[2025-12-03 03:48:54,680][src.alfred.alfred_evaluator][INFO] - Evaluating (16/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Mug-None-SideTable-21/trial_T20190909_090729_088825
Resetting ThorEnv
[2025-12-03 03:48:58,437][src.alfred.alfred_evaluator][INFO] - Task: Put a heated mug on the small black table, left of the tomato. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:48:58,444][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 47%|████████████████████████████████████████████████████████████████                                                                        | 16/34 [01:13<01:00,  3.35s/it][2025-12-03 03:48:58,444][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-TissueBox-Plate-DiningTable-203/trial_T20190909_141915_002879'}
[2025-12-03 03:48:58,676][src.alfred.alfred_evaluator][INFO] - Evaluating (17/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TissueBox-Plate-DiningTable-203/trial_T20190909_141915_002879
Resetting ThorEnv
[2025-12-03 03:49:13,456][src.alfred.alfred_evaluator][INFO] - Task: take a dish to the table to put tissue box on it
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:13,464][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 50%|████████████████████████████████████████████████████████████████████                                                                    | 17/34 [01:28<01:56,  6.86s/it][2025-12-03 03:49:13,464][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_heat_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190909_115736_122556'}
[2025-12-03 03:49:13,478][src.alfred.alfred_evaluator][INFO] - Evaluating (18/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190909_115736_122556
Resetting ThorEnv
[2025-12-03 03:49:16,545][src.alfred.alfred_evaluator][INFO] - Task: Put a sliced egg inside the sink
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:16,555][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 53%|████████████████████████████████████████████████████████████████████████                                                                | 18/34 [01:31<01:31,  5.73s/it][2025-12-03 03:49:16,556][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_with_movable_recep-TomatoSliced-Bowl-Fridge-20/trial_T20190907_060455_935544'}
[2025-12-03 03:49:16,566][src.alfred.alfred_evaluator][INFO] - Evaluating (19/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TomatoSliced-Bowl-Fridge-20/trial_T20190907_060455_935544
Resetting ThorEnv
[2025-12-03 03:49:20,608][src.alfred.alfred_evaluator][INFO] - Task: Refrigerate a tomato slice in a bowl
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:20,620][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 56%|████████████████████████████████████████████████████████████████████████████                                                            | 19/34 [01:35<01:18,  5.23s/it][2025-12-03 03:49:20,620][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-AppleSliced-Plate-Fridge-13/trial_T20190919_001342_371546'}
[2025-12-03 03:49:20,633][src.alfred.alfred_evaluator][INFO] - Evaluating (20/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-AppleSliced-Plate-Fridge-13/trial_T20190919_001342_371546
Resetting ThorEnv
[2025-12-03 03:49:23,603][src.alfred.alfred_evaluator][INFO] - Task: Put a slice of apple on a plate in the fridge.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:23,610][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 59%|████████████████████████████████████████████████████████████████████████████████                                                        | 20/34 [01:38<01:03,  4.56s/it][2025-12-03 03:49:23,610][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_with_movable_recep-Spatula-Pan-CounterTop-17/trial_T20190906_194903_710920'}
[2025-12-03 03:49:23,616][src.alfred.alfred_evaluator][INFO] - Evaluating (21/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-Spatula-Pan-CounterTop-17/trial_T20190906_194903_710920
Resetting ThorEnv
[2025-12-03 03:49:26,327][src.alfred.alfred_evaluator][INFO] - Task: Plan a pan with a spatula in it down on the counter to the right of the toaster.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:26,335][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 62%|████████████████████████████████████████████████████████████████████████████████████                                                    | 21/34 [01:40<00:52,  4.01s/it][2025-12-03 03:49:26,335][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Fork-None-Drawer-8/trial_T20190908_132152_999725'}
[2025-12-03 03:49:26,344][src.alfred.alfred_evaluator][INFO] - Evaluating (22/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Fork-None-Drawer-8/trial_T20190908_132152_999725
Resetting ThorEnv
[2025-12-03 03:49:29,119][src.alfred.alfred_evaluator][INFO] - Task: Wash the fork.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:29,127][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 65%|████████████████████████████████████████████████████████████████████████████████████████                                                | 22/34 [01:43<00:43,  3.64s/it][2025-12-03 03:49:29,128][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_heat_then_place_in_recep-Tomato-None-Fridge-24/trial_T20190908_033721_967359'}
[2025-12-03 03:49:29,139][src.alfred.alfred_evaluator][INFO] - Evaluating (23/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Tomato-None-Fridge-24/trial_T20190908_033721_967359
Resetting ThorEnv
[2025-12-03 03:49:31,217][src.alfred.alfred_evaluator][INFO] - Task: Put a cooked tomato into the refrigerator.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:31,225][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 68%|████████████████████████████████████████████████████████████████████████████████████████████                                            | 23/34 [01:45<00:34,  3.18s/it][2025-12-03 03:49:31,226][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Cloth-None-BathtubBasin-405/trial_T20190906_162502_940304'}
[2025-12-03 03:49:31,230][src.alfred.alfred_evaluator][INFO] - Evaluating (24/34): alfred/data/json_2.1.0/pick_and_place_simple-Cloth-None-BathtubBasin-405/trial_T20190906_162502_940304
Resetting ThorEnv
[2025-12-03 03:49:32,436][src.alfred.alfred_evaluator][INFO] - Task: place a rag inside the tub
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:32,443][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 71%|████████████████████████████████████████████████████████████████████████████████████████████████                                        | 24/34 [01:47<00:25,  2.59s/it][2025-12-03 03:49:32,444][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_with_movable_recep-TomatoSliced-Pan-Fridge-11/trial_T20190909_011522_113515'}
[2025-12-03 03:49:32,457][src.alfred.alfred_evaluator][INFO] - Evaluating (25/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TomatoSliced-Pan-Fridge-11/trial_T20190909_011522_113515
Resetting ThorEnv
[2025-12-03 03:49:35,289][src.alfred.alfred_evaluator][INFO] - Task: To place a pan with a tomato slice in it in the fridge.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:35,296][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 25/34 [01:49<00:24,  2.67s/it][2025-12-03 03:49:35,297][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-Ladle-None-DiningTable-27/trial_T20190911_131350_027076'}
[2025-12-03 03:49:35,306][src.alfred.alfred_evaluator][INFO] - Evaluating (26/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Ladle-None-DiningTable-27/trial_T20190911_131350_027076
Resetting ThorEnv
[2025-12-03 03:49:37,776][src.alfred.alfred_evaluator][INFO] - Task: Place a clean ladle on a table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:37,784][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 26/34 [01:52<00:20,  2.61s/it][2025-12-03 03:49:37,784][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-AppleSliced-None-DiningTable-27/trial_T20190907_151802_277016'}
[2025-12-03 03:49:37,795][src.alfred.alfred_evaluator][INFO] - Evaluating (27/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-AppleSliced-None-DiningTable-27/trial_T20190907_151802_277016
Resetting ThorEnv
[2025-12-03 03:49:39,719][src.alfred.alfred_evaluator][INFO] - Task: Cut an apple with a knife, wash the apple slice, place the apple slice on the table
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:39,726][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 27/34 [01:54<00:16,  2.41s/it][2025-12-03 03:49:39,726][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106'}
[2025-12-03 03:49:39,732][src.alfred.alfred_evaluator][INFO] - Evaluating (28/34): alfred/data/json_2.1.0/pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106
Resetting ThorEnv
[2025-12-03 03:49:41,777][src.alfred.alfred_evaluator][INFO] - Task: Place a newspaper on a couch.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:41,788][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 28/34 [01:56<00:13,  2.31s/it][2025-12-03 03:49:41,789][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_heat_then_place_in_recep-Mug-None-CoffeeMachine-1/trial_T20190907_222640_487432'}
[2025-12-03 03:49:41,798][src.alfred.alfred_evaluator][INFO] - Evaluating (29/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Mug-None-CoffeeMachine-1/trial_T20190907_222640_487432
Resetting ThorEnv
[2025-12-03 03:49:44,007][src.alfred.alfred_evaluator][INFO] - Task: Warm up the cup on the coffee maker.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:49:44,015][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 29/34 [01:58<00:11,  2.28s/it][2025-12-03 03:49:44,015][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_clean_then_place_in_recep-ButterKnife-None-Drawer-30/trial_T20190908_052007_212776'}
[2025-12-03 03:49:44,023][src.alfred.alfred_evaluator][INFO] - Evaluating (30/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-ButterKnife-None-Drawer-30/trial_T20190908_052007_212776
Resetting ThorEnv
[2025-12-03 03:50:03,411][src.alfred.alfred_evaluator][INFO] - Task: Place a rinsed knife inside a drawer.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:50:03,418][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 30/34 [02:18<00:29,  7.42s/it][2025-12-03 03:50:03,418][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934'}
[2025-12-03 03:50:03,425][src.alfred.alfred_evaluator][INFO] - Evaluating (31/34): alfred/data/json_2.1.0/pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934
Resetting ThorEnv
[2025-12-03 03:50:05,027][src.alfred.alfred_evaluator][INFO] - Task: Place a candle on top of the toilet.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:50:05,034][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 31/34 [02:19<00:17,  5.68s/it][2025-12-03 03:50:05,034][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-DishSponge-Pot-SinkBasin-1/trial_T20190908_103955_680867'}
[2025-12-03 03:50:05,046][src.alfred.alfred_evaluator][INFO] - Evaluating (32/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-DishSponge-Pot-SinkBasin-1/trial_T20190908_103955_680867
Resetting ThorEnv
[2025-12-03 03:50:06,899][src.alfred.alfred_evaluator][INFO] - Task: Move the pot with the green sponge from the refrigerator to the sink.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:50:06,906][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 32/34 [02:21<00:09,  4.54s/it][2025-12-03 03:50:06,907][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_cool_then_place_in_recep-Cup-None-SideTable-21/trial_T20190906_192823_237997'}
[2025-12-03 03:50:06,931][src.alfred.alfred_evaluator][INFO] - Evaluating (33/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-Cup-None-SideTable-21/trial_T20190906_192823_237997
Resetting ThorEnv
[2025-12-03 03:50:10,004][src.alfred.alfred_evaluator][INFO] - Task: Put a chilled vase on the three tiered black table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:50:10,011][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 33/34 [02:24<00:04,  4.11s/it][2025-12-03 03:50:10,012][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Cloth-None-Drawer-423/trial_T20190908_140701_251653'}
[2025-12-03 03:50:10,021][src.alfred.alfred_evaluator][INFO] - Evaluating (34/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Cloth-None-Drawer-423/trial_T20190908_140701_251653
Resetting ThorEnv
[2025-12-03 03:50:34,041][src.alfred.alfred_evaluator][INFO] - Task: Put a clean cloth in a drawer.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 219, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 137, in score
    output = self.model(sentence_tokens.input_ids, attention_mask=sentence_tokens.attention_mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)
[2025-12-03 03:50:34,048][src.alfred.alfred_evaluator][INFO] - Error: RuntimeError('Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)')
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [02:48<00:00, 10.09s/it]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [02:48<00:00,  4.96s/it]
[2025-12-03 03:50:34,049][src.alfred.alfred_evaluator][INFO] - []
Error executing job with overrides: []
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/evaluate.py", line 31, in main
    evaluator.evaluate()
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 104, in evaluate
    log.info(f'success rate: {n_success / n * 100:.2f} % ({n_success}/{n})')
                              ~~~~~~~~~~^~~
ZeroDivisionError: division by zero

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
