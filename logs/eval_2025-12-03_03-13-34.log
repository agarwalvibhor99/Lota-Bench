/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config_alfred': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
{'planner': {'model_name': '/notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507', 'use_accelerate_device_map': True, 'load_in_8bit': True, 'device': 'cuda', 'max_steps': 25, 'random_seed': 0, 'scoring_batch_size': 4, 'score_function': 'sum', 'scoring_mode': 'guidance', 'use_predefined_prompt': False, 'hf_auth_token': '', 'openai_api_key': ''}, 'name': 'alfred', 'out_dir': '${hydra:run.dir}', 'prompt': {'num_examples': 6, 'splitter': '', 'prefix': "Robot: Hi there, I'm a robot operating in a home.\nRobot: You can ask me to do various tasks and I'll tell you the sequence of actions I would do to accomplish your task.\n", 'example_file_path': 'resource/alfred_examples_for_prompt.json'}, 'alfred': {'x_display': '1', 'eval_set': 'valid_seen', 'eval_portion_in_percent': 5, 'random_seed_for_eval_subset': 1}}
[2025-12-03 03:13:42,193][src.alfred.alfred_evaluator][INFO] - planner:
  model_name: /notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507
  use_accelerate_device_map: true
  load_in_8bit: true
  device: cuda
  max_steps: 25
  random_seed: 0
  scoring_batch_size: 4
  score_function: sum
  scoring_mode: guidance
  use_predefined_prompt: false
  hf_auth_token: ''
  openai_api_key: ''
name: alfred
out_dir: ${hydra:run.dir}
prompt:
  num_examples: 6
  splitter: ''
  prefix: 'Robot: Hi there, I''m a robot operating in a home.

    Robot: You can ask me to do various tasks and I''ll tell you the sequence of actions
    I would do to accomplish your task.

    '
  example_file_path: resource/alfred_examples_for_prompt.json
alfred:
  x_display: '1'
  eval_set: valid_seen
  eval_portion_in_percent: 5
  random_seed_for_eval_subset: 1

/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Loading LLM and tokenizer: /notebooks/LLMTaskPlanning/models/Qwen3-4B-Instruct-2507
[2025-12-03 03:13:46,473][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████████████████                                                                          | 1/3 [00:10<00:20, 10.39s/it]Loading checkpoint shards:  67%|██████████████████████████████████████████████████████████████████████████                                     | 2/3 [00:21<00:10, 10.54s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  5.88s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  7.12s/it]
[2025-12-03 03:14:09,894][src.alfred.alfred_task_planner][INFO] - # of skills: 214
[2025-12-03 03:14:09,894][src.alfred.alfred_task_planner][INFO] - [' done', ' find a toilet', ' find a cabinet', ' find a candle', ' find a tennis racket', ' find a tissue box', ' find a cup', ' find a sofa', ' find a tomato', ' find a shelf', ' find a plate', ' find a bathtub', ' find an egg', ' find a salt shaker', ' find a credit card', ' find a box', ' find a watch', ' find a ladle', ' find a toilet paper', ' find a book', ' find a key chain', ' find a wine bottle', ' find a cloth', ' find a stove burner', ' find a pot', ' find a glassbottle', ' find a newspaper', ' find a bowl', ' find a pan', ' find a baseball bat', ' find a microwave', ' find a desk lamp', ' find a bread', ' find a garbage can', ' find a soap bottle', ' find a dresser', ' find a kettle', ' find a laptop', ' find a toilet paper hanger', ' find a fork', ' find a dining table', ' find a basket ball', ' find a fridge', ' find a sink', ' find a drawer', ' find a watering can', ' find a pencil', ' find a cell phone', ' find a mug', ' find a butter knife', ' find a plunger', ' find a statue', ' find a vase', ' find a hand towel', ' find a spray bottle', ' find a spatula', ' find a dish sponge', ' find a counter top', ' find an alarm clock', ' find a potato', ' find a side table', ' find a desk', ' find a coffee table', ' find an ottoman', ' find an apple', ' find a spoon', ' find a floor lamp', ' find a soap bar', ' find a CD', ' find a knife', ' find a cart', ' find a faucet', ' find a coffee machine', ' find a safe', ' find a remote control', ' find a pillow', ' find a pepper shaker', ' find a pen', ' find a lettuce', ' find a bed', ' find an arm chair', ' pick up the key chain', ' put down the key chain', ' pick up the potato', ' put down the potato', ' pick up the pot', ' put down the pot', ' pick up the pen', ' put down the pen', ' pick up the candle', ' put down the candle', ' pick up the CD', ' put down the CD', ' pick up the pan', ' put down the pan', ' pick up the watch', ' put down the watch', ' pick up the newspaper', ' put down the newspaper', ' pick up the hand towel', ' put down the hand towel', ' pick up the spray bottle', ' put down the spray bottle', ' pick up the baseball bat', ' put down the baseball bat', ' pick up the bread', ' put down the bread', ' pick up the cell phone', ' put down the cell phone', ' pick up the book', ' put down the book', ' pick up the lettuce', ' put down the lettuce', ' pick up the credit card', ' put down the credit card', ' pick up the mug', ' put down the mug', ' pick up the alarm clock', ' put down the alarm clock', ' pick up the kettle', ' put down the kettle', ' pick up the toilet paper', ' put down the toilet paper', ' pick up the bowl', ' put down the bowl', ' pick up the fork', ' put down the fork', ' pick up the box', ' put down the box', ' pick up the egg', ' put down the egg', ' pick up the spoon', ' put down the spoon', ' pick up the tissue box', ' put down the tissue box', ' pick up the apple', ' put down the apple', ' pick up the tennis racket', ' put down the tennis racket', ' pick up the ladle', ' put down the ladle', ' pick up the wine bottle', ' put down the wine bottle', ' pick up the cloth', ' put down the cloth', ' pick up the plunger', ' put down the plunger', ' pick up the soap bar', ' put down the soap bar', ' pick up the pencil', ' put down the pencil', ' pick up the laptop', ' put down the laptop', ' pick up the remote control', ' put down the remote control', ' pick up the basket ball', ' put down the basket ball', ' pick up the dish sponge', ' put down the dish sponge', ' pick up the cup', ' put down the cup', ' pick up the spatula', ' put down the spatula', ' pick up the salt shaker', ' put down the salt shaker', ' pick up the plate', ' put down the plate', ' pick up the pepper shaker', ' put down the pepper shaker', ' pick up the pillow', ' put down the pillow', ' pick up the glassbottle', ' put down the glassbottle', ' pick up the soap bottle', ' put down the soap bottle', ' pick up the knife', ' put down the knife', ' pick up the statue', ' put down the statue', ' pick up the tomato', ' put down the tomato', ' pick up the butter knife', ' put down the butter knife', ' pick up the watering can', ' put down the watering can', ' pick up the vase', ' put down the vase', ' open the safe', ' close the safe', ' open the laptop', ' close the laptop', ' open the fridge', ' close the fridge', ' open the box', ' close the box', ' open the microwave', ' close the microwave', ' open the cabinet', ' close the cabinet', ' open the drawer', ' close the drawer', ' slice the potato', ' slice the lettuce', ' slice the tomato', ' slice the apple', ' slice the bread', ' turn on the microwave', ' turn off the microwave', ' turn on the desk lamp', ' turn off the desk lamp', ' turn on the floor lamp', ' turn off the floor lamp', ' turn on the faucet', ' turn off the faucet']
Found path: /root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64
Mono path[0] = '/root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64_Data/Managed'
Mono config path = '/root/.ai2thor/releases/thor-201909061227-Linux64/thor-201909061227-Linux64_Data/Mono/etc'
Unable to preload the following plugins:
	ScreenSelector.so
Display 0 'screen': 1024x768 (primary device).
Logging to /root/.config/unity3d/Allen Institute for Artificial Intelligence/AI2-Thor/Player.log
ALSA lib confmisc.c:855:(parse_card) cannot find card '0'
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory
ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory
ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default
ALSA lib confmisc.c:855:(parse_card) cannot find card '0'
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory
ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name
ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory
ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default
{'tests_seen': 1533,
 'tests_unseen': 1529,
 'train': 21023,
 'valid_seen': 820,
 'valid_unseen': 821}
ThorEnv started.
  0%|                                                                                                                                                 | 0/34 [00:00<?, ?it/s][2025-12-03 03:14:16,692][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-SoapBar-None-Cart-401/trial_T20190907_054906_608944'}
[2025-12-03 03:14:16,699][src.alfred.alfred_evaluator][INFO] - Evaluating (1/34): alfred/data/json_2.1.0/pick_and_place_simple-SoapBar-None-Cart-401/trial_T20190907_054906_608944
Resetting ThorEnv
[2025-12-03 03:14:32,155][src.alfred.alfred_evaluator][INFO] - Task: To place the soap on the rack.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:14:32,799][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
  3%|████                                                                                                                                     | 1/34 [00:16<08:51, 16.11s/it][2025-12-03 03:14:32,799][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 5, 'task': 'pick_cool_then_place_in_recep-Plate-None-Cabinet-27/trial_T20190906_173120_350651'}
[2025-12-03 03:14:32,812][src.alfred.alfred_evaluator][INFO] - Evaluating (2/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-Plate-None-Cabinet-27/trial_T20190906_173120_350651
Resetting ThorEnv
[2025-12-03 03:14:46,495][src.alfred.alfred_evaluator][INFO] - Task: Put a plate in a cabinet.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:14:46,725][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
  6%|████████                                                                                                                                 | 2/34 [00:30<07:54, 14.82s/it][2025-12-03 03:14:46,725][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Book-None-Sofa-229/trial_T20190907_042856_259139'}
[2025-12-03 03:14:46,730][src.alfred.alfred_evaluator][INFO] - Evaluating (3/34): alfred/data/json_2.1.0/pick_and_place_simple-Book-None-Sofa-229/trial_T20190907_042856_259139
Resetting ThorEnv
[2025-12-03 03:14:55,807][src.alfred.alfred_evaluator][INFO] - Task: Move a book from a desk to a sofa.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:14:56,033][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
  9%|████████████                                                                                                                             | 3/34 [00:39<06:21, 12.31s/it][2025-12-03 03:14:56,034][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-DishSponge-None-Cart-401/trial_T20190907_024634_972453'}
[2025-12-03 03:14:56,045][src.alfred.alfred_evaluator][INFO] - Evaluating (4/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-DishSponge-None-Cart-401/trial_T20190907_024634_972453
Resetting ThorEnv
[2025-12-03 03:14:58,965][src.alfred.alfred_evaluator][INFO] - Task: Put a clean sponge on a metal rack.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:14:59,266][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 12%|████████████████                                                                                                                         | 4/34 [00:42<04:21,  8.72s/it][2025-12-03 03:14:59,266][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_cool_then_place_in_recep-BreadSliced-None-DiningTable-27/trial_T20190908_075813_148407'}
[2025-12-03 03:14:59,279][src.alfred.alfred_evaluator][INFO] - Evaluating (5/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-BreadSliced-None-DiningTable-27/trial_T20190908_075813_148407
Resetting ThorEnv
[2025-12-03 03:15:00,914][src.alfred.alfred_evaluator][INFO] - Task: Slice bread and chill it in the fridge. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:01,156][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 15%|████████████████████▏                                                                                                                    | 5/34 [00:44<03:01,  6.26s/it][2025-12-03 03:15:01,157][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-ToiletPaper-None-ToiletPaperHanger-415/trial_T20190908_050518_595510'}
[2025-12-03 03:15:01,160][src.alfred.alfred_evaluator][INFO] - Evaluating (6/34): alfred/data/json_2.1.0/pick_and_place_simple-ToiletPaper-None-ToiletPaperHanger-415/trial_T20190908_050518_595510
Resetting ThorEnv
[2025-12-03 03:15:04,412][src.alfred.alfred_evaluator][INFO] - Task: Put a roll of toilet paper on the toilet paper holder.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:04,668][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 18%|████████████████████████▏                                                                                                                | 6/34 [00:47<02:29,  5.33s/it][2025-12-03 03:15:04,668][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-ButterKnife-None-DiningTable-16/trial_T20190909_114508_617301'}
[2025-12-03 03:15:04,677][src.alfred.alfred_evaluator][INFO] - Evaluating (7/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-ButterKnife-None-DiningTable-16/trial_T20190909_114508_617301
Resetting ThorEnv
[2025-12-03 03:15:09,298][src.alfred.alfred_evaluator][INFO] - Task: Put a clean butter knife on a round white table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:09,556][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 21%|████████████████████████████▏                                                                                                            | 7/34 [00:52<02:19,  5.18s/it][2025-12-03 03:15:09,556][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-HandTowel-None-BathtubBasin-419/trial_T20190908_023400_293044'}
[2025-12-03 03:15:09,561][src.alfred.alfred_evaluator][INFO] - Evaluating (8/34): alfred/data/json_2.1.0/pick_and_place_simple-HandTowel-None-BathtubBasin-419/trial_T20190908_023400_293044
Resetting ThorEnv
[2025-12-03 03:15:13,501][src.alfred.alfred_evaluator][INFO] - Task: Place a towel in the bath tub.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:13,726][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 24%|████████████████████████████████▏                                                                                                        | 8/34 [00:57<02:06,  4.86s/it][2025-12-03 03:15:13,727][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106'}
[2025-12-03 03:15:13,737][src.alfred.alfred_evaluator][INFO] - Evaluating (9/34): alfred/data/json_2.1.0/pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106
Resetting ThorEnv
[2025-12-03 03:15:18,996][src.alfred.alfred_evaluator][INFO] - Task: Move a newspaper from a dresser to a black couch.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:19,267][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 26%|████████████████████████████████████▎                                                                                                    | 9/34 [01:02<02:06,  5.07s/it][2025-12-03 03:15:19,267][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934'}
[2025-12-03 03:15:19,272][src.alfred.alfred_evaluator][INFO] - Evaluating (10/34): alfred/data/json_2.1.0/pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934
Resetting ThorEnv
[2025-12-03 03:15:21,446][src.alfred.alfred_evaluator][INFO] - Task: Put a bottle on the back of a newspaper.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:21,676][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 29%|████████████████████████████████████████                                                                                                | 10/34 [01:04<01:42,  4.25s/it][2025-12-03 03:15:21,676][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_cool_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190907_073447_193556'}
[2025-12-03 03:15:21,697][src.alfred.alfred_evaluator][INFO] - Evaluating (11/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190907_073447_193556
Resetting ThorEnv
[2025-12-03 03:15:25,339][src.alfred.alfred_evaluator][INFO] - Task: Place a cold potato slice in the sink.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:25,662][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 32%|████████████████████████████████████████████                                                                                            | 11/34 [01:08<01:35,  4.17s/it][2025-12-03 03:15:25,662][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-Tomato-None-CounterTop-25/trial_T20190909_012550_586494'}
[2025-12-03 03:15:25,671][src.alfred.alfred_evaluator][INFO] - Evaluating (12/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Tomato-None-CounterTop-25/trial_T20190909_012550_586494
Resetting ThorEnv
[2025-12-03 03:15:28,801][src.alfred.alfred_evaluator][INFO] - Task: Put a cold, clean tomato on the counter.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:29,045][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 35%|████████████████████████████████████████████████                                                                                        | 12/34 [01:12<01:26,  3.93s/it][2025-12-03 03:15:29,045][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-Watch-Bowl-Shelf-326/trial_T20190909_031836_927615'}
[2025-12-03 03:15:29,051][src.alfred.alfred_evaluator][INFO] - Evaluating (13/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-Watch-Bowl-Shelf-326/trial_T20190909_031836_927615
Resetting ThorEnv
[2025-12-03 03:15:33,061][src.alfred.alfred_evaluator][INFO] - Task: Put a bowl with the watch in it on the shelf.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:33,315][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 38%|████████████████████████████████████████████████████                                                                                    | 13/34 [01:16<01:24,  4.03s/it][2025-12-03 03:15:33,316][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_simple-CreditCard-None-Drawer-227/trial_T20190909_010644_297017'}
[2025-12-03 03:15:33,323][src.alfred.alfred_evaluator][INFO] - Evaluating (14/34): alfred/data/json_2.1.0/pick_and_place_simple-CreditCard-None-Drawer-227/trial_T20190909_010644_297017
Resetting ThorEnv
[2025-12-03 03:15:36,888][src.alfred.alfred_evaluator][INFO] - Task: Place a credit card into a drawer
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:37,163][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 41%|████████████████████████████████████████████████████████                                                                                | 14/34 [01:20<01:19,  3.98s/it][2025-12-03 03:15:37,163][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Cloth-None-Toilet-413/trial_T20190908_175253_104175'}
[2025-12-03 03:15:37,182][src.alfred.alfred_evaluator][INFO] - Evaluating (15/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Cloth-None-Toilet-413/trial_T20190908_175253_104175
Resetting ThorEnv
[2025-12-03 03:15:40,292][src.alfred.alfred_evaluator][INFO] - Task: Put a clean rag on the toilet. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:40,534][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 44%|████████████████████████████████████████████████████████████                                                                            | 15/34 [01:23<01:12,  3.79s/it][2025-12-03 03:15:40,535][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_heat_then_place_in_recep-Mug-None-SideTable-21/trial_T20190909_090729_088825'}
[2025-12-03 03:15:40,995][src.alfred.alfred_evaluator][INFO] - Evaluating (16/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Mug-None-SideTable-21/trial_T20190909_090729_088825
Resetting ThorEnv
[2025-12-03 03:15:44,645][src.alfred.alfred_evaluator][INFO] - Task: Put a heated mug on the small black table, left of the tomato. 
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:15:44,955][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 47%|████████████████████████████████████████████████████████████████                                                                        | 16/34 [01:28<01:11,  3.98s/it][2025-12-03 03:15:44,955][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-TissueBox-Plate-DiningTable-203/trial_T20190909_141915_002879'}
[2025-12-03 03:15:44,980][src.alfred.alfred_evaluator][INFO] - Evaluating (17/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TissueBox-Plate-DiningTable-203/trial_T20190909_141915_002879
Resetting ThorEnv
[2025-12-03 03:16:00,095][src.alfred.alfred_evaluator][INFO] - Task: take a dish to the table to put tissue box on it
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:00,364][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 50%|████████████████████████████████████████████████████████████████████                                                                    | 17/34 [01:43<02:06,  7.42s/it][2025-12-03 03:16:00,365][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_heat_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190909_115736_122556'}
[2025-12-03 03:16:00,419][src.alfred.alfred_evaluator][INFO] - Evaluating (18/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-PotatoSliced-None-SinkBasin-13/trial_T20190909_115736_122556
Resetting ThorEnv
[2025-12-03 03:16:03,791][src.alfred.alfred_evaluator][INFO] - Task: Put a sliced egg inside the sink
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:04,035][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 53%|████████████████████████████████████████████████████████████████████████                                                                | 18/34 [01:47<01:40,  6.29s/it][2025-12-03 03:16:04,035][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_with_movable_recep-TomatoSliced-Bowl-Fridge-20/trial_T20190907_060455_935544'}
[2025-12-03 03:16:04,071][src.alfred.alfred_evaluator][INFO] - Evaluating (19/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TomatoSliced-Bowl-Fridge-20/trial_T20190907_060455_935544
Resetting ThorEnv
[2025-12-03 03:16:09,331][src.alfred.alfred_evaluator][INFO] - Task: Refrigerate a tomato slice in a bowl
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:09,588][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 56%|████████████████████████████████████████████████████████████████████████████                                                            | 19/34 [01:52<01:31,  6.07s/it][2025-12-03 03:16:09,588][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-AppleSliced-Plate-Fridge-13/trial_T20190919_001342_371546'}
[2025-12-03 03:16:09,615][src.alfred.alfred_evaluator][INFO] - Evaluating (20/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-AppleSliced-Plate-Fridge-13/trial_T20190919_001342_371546
Resetting ThorEnv
[2025-12-03 03:16:12,473][src.alfred.alfred_evaluator][INFO] - Task: Put a slice of apple on a plate in the fridge.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:12,745][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 59%|████████████████████████████████████████████████████████████████████████████████                                                        | 20/34 [01:56<01:12,  5.20s/it][2025-12-03 03:16:12,745][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_with_movable_recep-Spatula-Pan-CounterTop-17/trial_T20190906_194903_710920'}
[2025-12-03 03:16:12,751][src.alfred.alfred_evaluator][INFO] - Evaluating (21/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-Spatula-Pan-CounterTop-17/trial_T20190906_194903_710920
Resetting ThorEnv
[2025-12-03 03:16:16,150][src.alfred.alfred_evaluator][INFO] - Task: Plan a pan with a spatula in it down on the counter to the right of the toaster.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:16,416][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 62%|████████████████████████████████████████████████████████████████████████████████████                                                    | 21/34 [01:59<01:01,  4.74s/it][2025-12-03 03:16:16,416][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Fork-None-Drawer-8/trial_T20190908_132152_999725'}
[2025-12-03 03:16:16,424][src.alfred.alfred_evaluator][INFO] - Evaluating (22/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Fork-None-Drawer-8/trial_T20190908_132152_999725
Resetting ThorEnv
[2025-12-03 03:16:19,597][src.alfred.alfred_evaluator][INFO] - Task: Wash the fork.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:19,827][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 65%|████████████████████████████████████████████████████████████████████████████████████████                                                | 22/34 [02:03<00:52,  4.34s/it][2025-12-03 03:16:19,827][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_heat_then_place_in_recep-Tomato-None-Fridge-24/trial_T20190908_033721_967359'}
[2025-12-03 03:16:19,844][src.alfred.alfred_evaluator][INFO] - Evaluating (23/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Tomato-None-Fridge-24/trial_T20190908_033721_967359
Resetting ThorEnv
[2025-12-03 03:16:22,071][src.alfred.alfred_evaluator][INFO] - Task: Put a cooked tomato into the refrigerator.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:22,342][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 68%|████████████████████████████████████████████████████████████████████████████████████████████                                            | 23/34 [02:05<00:41,  3.79s/it][2025-12-03 03:16:22,343][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Cloth-None-BathtubBasin-405/trial_T20190906_162502_940304'}
[2025-12-03 03:16:22,348][src.alfred.alfred_evaluator][INFO] - Evaluating (24/34): alfred/data/json_2.1.0/pick_and_place_simple-Cloth-None-BathtubBasin-405/trial_T20190906_162502_940304
Resetting ThorEnv
[2025-12-03 03:16:23,765][src.alfred.alfred_evaluator][INFO] - Task: place a rag inside the tub
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:24,007][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 71%|████████████████████████████████████████████████████████████████████████████████████████████████                                        | 24/34 [02:07<00:31,  3.15s/it][2025-12-03 03:16:24,007][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_with_movable_recep-TomatoSliced-Pan-Fridge-11/trial_T20190909_011522_113515'}
[2025-12-03 03:16:24,043][src.alfred.alfred_evaluator][INFO] - Evaluating (25/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-TomatoSliced-Pan-Fridge-11/trial_T20190909_011522_113515
Resetting ThorEnv
[2025-12-03 03:16:27,475][src.alfred.alfred_evaluator][INFO] - Task: To place a pan with a tomato slice in it in the fridge.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:27,711][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 25/34 [02:11<00:29,  3.32s/it][2025-12-03 03:16:27,711][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_clean_then_place_in_recep-Ladle-None-DiningTable-27/trial_T20190911_131350_027076'}
[2025-12-03 03:16:27,741][src.alfred.alfred_evaluator][INFO] - Evaluating (26/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Ladle-None-DiningTable-27/trial_T20190911_131350_027076
Resetting ThorEnv
[2025-12-03 03:16:29,661][src.alfred.alfred_evaluator][INFO] - Task: Place a clean ladle on a table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:29,921][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 26/34 [02:13<00:23,  2.99s/it][2025-12-03 03:16:29,922][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-AppleSliced-None-DiningTable-27/trial_T20190907_151802_277016'}
[2025-12-03 03:16:29,934][src.alfred.alfred_evaluator][INFO] - Evaluating (27/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-AppleSliced-None-DiningTable-27/trial_T20190907_151802_277016
Resetting ThorEnv
[2025-12-03 03:16:31,696][src.alfred.alfred_evaluator][INFO] - Task: Cut an apple with a knife, wash the apple slice, place the apple slice on the table
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:31,943][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 27/34 [02:15<00:18,  2.70s/it][2025-12-03 03:16:31,944][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106'}
[2025-12-03 03:16:31,951][src.alfred.alfred_evaluator][INFO] - Evaluating (28/34): alfred/data/json_2.1.0/pick_and_place_simple-Newspaper-None-Sofa-224/trial_T20190909_111324_949106
Resetting ThorEnv
[2025-12-03 03:16:34,520][src.alfred.alfred_evaluator][INFO] - Task: Place a newspaper on a couch.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:34,779][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 28/34 [02:18<00:16,  2.74s/it][2025-12-03 03:16:34,779][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_heat_then_place_in_recep-Mug-None-CoffeeMachine-1/trial_T20190907_222640_487432'}
[2025-12-03 03:16:34,792][src.alfred.alfred_evaluator][INFO] - Evaluating (29/34): alfred/data/json_2.1.0/pick_heat_then_place_in_recep-Mug-None-CoffeeMachine-1/trial_T20190907_222640_487432
Resetting ThorEnv
[2025-12-03 03:16:38,400][src.alfred.alfred_evaluator][INFO] - Task: Warm up the cup on the coffee maker.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:16:38,648][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 29/34 [02:21<00:15,  3.08s/it][2025-12-03 03:16:38,648][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 0, 'task': 'pick_clean_then_place_in_recep-ButterKnife-None-Drawer-30/trial_T20190908_052007_212776'}
[2025-12-03 03:16:38,659][src.alfred.alfred_evaluator][INFO] - Evaluating (30/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-ButterKnife-None-Drawer-30/trial_T20190908_052007_212776
Resetting ThorEnv
[2025-12-03 03:17:08,639][src.alfred.alfred_evaluator][INFO] - Task: Place a rinsed knife inside a drawer.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:17:08,893][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 30/34 [02:52<00:44, 11.23s/it][2025-12-03 03:17:08,894][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934'}
[2025-12-03 03:17:08,898][src.alfred.alfred_evaluator][INFO] - Evaluating (31/34): alfred/data/json_2.1.0/pick_and_place_simple-Candle-None-Toilet-429/trial_T20190908_052232_887934
Resetting ThorEnv
[2025-12-03 03:17:11,180][src.alfred.alfred_evaluator][INFO] - Task: Place a candle on top of the toilet.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:17:11,448][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 31/34 [02:54<00:25,  8.63s/it][2025-12-03 03:17:11,449][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 1, 'task': 'pick_and_place_with_movable_recep-DishSponge-Pot-SinkBasin-1/trial_T20190908_103955_680867'}
[2025-12-03 03:17:11,469][src.alfred.alfred_evaluator][INFO] - Evaluating (32/34): alfred/data/json_2.1.0/pick_and_place_with_movable_recep-DishSponge-Pot-SinkBasin-1/trial_T20190908_103955_680867
Resetting ThorEnv
[2025-12-03 03:17:13,636][src.alfred.alfred_evaluator][INFO] - Task: Move the pot with the green sponge from the refrigerator to the sink.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:17:13,887][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 32/34 [02:57<00:13,  6.77s/it][2025-12-03 03:17:13,887][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_cool_then_place_in_recep-Cup-None-SideTable-21/trial_T20190906_192823_237997'}
[2025-12-03 03:17:13,901][src.alfred.alfred_evaluator][INFO] - Evaluating (33/34): alfred/data/json_2.1.0/pick_cool_then_place_in_recep-Cup-None-SideTable-21/trial_T20190906_192823_237997
Resetting ThorEnv
[2025-12-03 03:17:18,604][src.alfred.alfred_evaluator][INFO] - Task: Put a chilled vase on the three tiered black table.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:17:18,872][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 33/34 [03:02<00:06,  6.23s/it][2025-12-03 03:17:18,872][src.alfred.alfred_evaluator][INFO] - {'repeat_idx': 2, 'task': 'pick_clean_then_place_in_recep-Cloth-None-Drawer-423/trial_T20190908_140701_251653'}
[2025-12-03 03:17:18,879][src.alfred.alfred_evaluator][INFO] - Evaluating (34/34): alfred/data/json_2.1.0/pick_clean_then_place_in_recep-Cloth-None-Drawer-423/trial_T20190908_140701_251653
Resetting ThorEnv
[2025-12-03 03:17:47,102][src.alfred.alfred_evaluator][INFO] - Task: Put a clean cloth in a drawer.
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 135, in evaluate_main
    result = self.evaluate_task(env, traj_data, r_idx, model_args, planner, save_path, log_prompt=(i==0), train_gt_steps=train_gt_steps)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 190, in evaluate_task
    step, prompt = planner.plan_step_by_step(instruction_text, prev_steps, prev_action_msg)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 212, in plan_step_by_step
    scores = self.score(prompt, self.skill_set)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/src/task_planner.py", line 89, in score
    scores = out['score']
             ~~~^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program.py", line 470, in __getitem__
    return self._variables[key]
           ~~~~~~~~~~~~~~~^^^^^
KeyError: 'score'
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 109, in run
    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 559, in visit
    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in visit
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 266, in <listcomp>
    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/_program_executor.py", line 379, in visit
    command_output = await command_function(*positional_args, **named_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 151, in select
    option_logprobs = await recursive_select([])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/library/_select.py", line 107, in recursive_select
    gen_obj = await parser.llm_session(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/guidance/llms/_transformers.py", line 335, in __call__
    generated_sequence = self.llm.model_obj.generate(**generate_args)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2543, in generate
    prepared_logits_processor = self._get_logits_processor(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1267, in _get_logits_processor
    processors.append(TemperatureLogitsWarper(generation_config.temperature))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/LLMTaskPlanning/lota-bench-venv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 287, in __init__
    raise ValueError(except_msg)
ValueError: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.

Error in program:  `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.
[2025-12-03 03:17:47,390][src.alfred.alfred_evaluator][INFO] - Error: KeyError('score')
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [03:30<00:00, 12.92s/it]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [03:30<00:00,  6.20s/it]
[2025-12-03 03:17:47,391][src.alfred.alfred_evaluator][INFO] - []
Error executing job with overrides: []
Traceback (most recent call last):
  File "/notebooks/LLMTaskPlanning/src/evaluate.py", line 31, in main
    evaluator.evaluate()
  File "/notebooks/LLMTaskPlanning/src/alfred/alfred_evaluator.py", line 104, in evaluate
    log.info(f'success rate: {n_success / n * 100:.2f} % ({n_success}/{n})')
                              ~~~~~~~~~~^~~
ZeroDivisionError: division by zero

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
